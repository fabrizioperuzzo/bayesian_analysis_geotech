{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>σ^v_[kPa]</th>\n",
       "      <th>PI</th>\n",
       "      <th>LL</th>\n",
       "      <th>wn</th>\n",
       "      <th>OCR</th>\n",
       "      <th>Cu-Tx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27.000</td>\n",
       "      <td>41.090909</td>\n",
       "      <td>66.545455</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>5.730159</td>\n",
       "      <td>68.744449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>27.000</td>\n",
       "      <td>43.454545</td>\n",
       "      <td>69.727273</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>5.730159</td>\n",
       "      <td>68.744449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>27.000</td>\n",
       "      <td>45.818182</td>\n",
       "      <td>72.909091</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.730159</td>\n",
       "      <td>68.744449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>28.000</td>\n",
       "      <td>48.181818</td>\n",
       "      <td>76.090909</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.730159</td>\n",
       "      <td>68.744449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>31.500</td>\n",
       "      <td>50.545455</td>\n",
       "      <td>79.272727</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.730159</td>\n",
       "      <td>68.744449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>315.875</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>41.933333</td>\n",
       "      <td>2.009089</td>\n",
       "      <td>221.478496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>461</td>\n",
       "      <td>316.750</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>42.966667</td>\n",
       "      <td>2.018177</td>\n",
       "      <td>222.835221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>462</td>\n",
       "      <td>317.000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2.027266</td>\n",
       "      <td>224.191945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>463</td>\n",
       "      <td>317.500</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>77.466667</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.036354</td>\n",
       "      <td>225.548670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>464</td>\n",
       "      <td>317.500</td>\n",
       "      <td>49.800000</td>\n",
       "      <td>76.733333</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2.045443</td>\n",
       "      <td>226.905395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     σ^v_[kPa]         PI         LL         wn       OCR       Cu-Tx\n",
       "3       27.000  41.090909  66.545455  29.200000  5.730159   68.744449\n",
       "4       27.000  43.454545  69.727273  29.600000  5.730159   68.744449\n",
       "5       27.000  45.818182  72.909091  30.000000  5.730159   68.744449\n",
       "6       28.000  48.181818  76.090909  30.000000  5.730159   68.744449\n",
       "7       31.500  50.545455  79.272727  30.000000  5.730159   68.744449\n",
       "..         ...        ...        ...        ...       ...         ...\n",
       "460    315.875  50.000000  76.000000  41.933333  2.009089  221.478496\n",
       "461    316.750  50.000000  76.000000  42.966667  2.018177  222.835221\n",
       "462    317.000  50.000000  76.000000  44.000000  2.027266  224.191945\n",
       "463    317.500  49.600000  77.466667  42.000000  2.036354  225.548670\n",
       "464    317.500  49.800000  76.733333  43.000000  2.045443  226.905395\n",
       "\n",
       "[462 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# dfg.to_hdf('dfg3_4.h5', key='losses')\n",
    "\n",
    "dfg = pd.read_hdf('dfg3_4.h5', key='losses')\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import statsmodels as sm\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "#matplotlib.style.use('ggplot')\n",
    "\n",
    "# Create models from data\n",
    "def best_fit_distribution(data, bins=10, ax=None):\n",
    "    \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "    # Get histogram of original data\n",
    "    y, x = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "    # Distributions to check\n",
    "    DISTRIBUTIONS_ALL = [        \n",
    "        st.alpha,st.anglit,st.arcsine,st.beta,st.betaprime,st.bradford,st.burr,st.cauchy,st.chi,st.chi2,st.cosine,\n",
    "        st.dgamma,st.dweibull,st.erlang,st.expon,st.exponnorm,st.exponweib,st.exponpow,st.f,st.fatiguelife,st.fisk,\n",
    "        st.foldcauchy,st.foldnorm,st.frechet_r,st.frechet_l,st.genlogistic,st.genpareto,st.gennorm,st.genexpon,\n",
    "        st.genextreme,st.gausshyper,st.gamma,st.gengamma,st.genhalflogistic,st.gilbrat,st.gompertz,st.gumbel_r,\n",
    "        st.gumbel_l,st.halfcauchy,st.halflogistic,st.halfnorm,st.halfgennorm,st.hypsecant,st.invgamma,st.invgauss,\n",
    "        st.invweibull,st.johnsonsb,st.johnsonsu,st.ksone,st.kstwobign,st.laplace,st.levy,st.levy_l,st.levy_stable,\n",
    "        st.logistic,st.loggamma,st.loglaplace,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,\n",
    "        st.nct,st.norm,st.pareto,st.pearson3,st.powerlaw,st.powerlognorm,st.powernorm,st.rdist,st.reciprocal,\n",
    "        st.rayleigh,st.rice,st.recipinvgauss,st.semicircular,st.t,st.triang,st.truncexpon,st.truncnorm,st.tukeylambda,\n",
    "        st.uniform,st.vonmises,st.vonmises_line,st.wald,st.weibull_min,st.weibull_max,st.wrapcauchy]\n",
    "    \n",
    "    # Distributions available in pymc3\n",
    "    DISTRIBUTIONS = [    \n",
    "        st.uniform, st.norm, st.halfnorm, st.gamma, st.expon, st.cauchy]\n",
    "    \n",
    "    # Distributions available in pymc3\n",
    "#     DISTRIBUTIONS = [st.norm]\n",
    "\n",
    "\n",
    "    # Best holders\n",
    "    best_distribution = st.norm\n",
    "    best_params = (0.0, 1.0)\n",
    "    best_sse = np.inf\n",
    "\n",
    "    # Estimate distribution parameters from data\n",
    "    for distribution in DISTRIBUTIONS:\n",
    "\n",
    "        # Try to fit the distribution\n",
    "        try:\n",
    "            # Ignore warnings from data that can't be fit\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "\n",
    "                # fit dist to data\n",
    "                params = distribution.fit(data)\n",
    "\n",
    "                # Separate parts of parameters\n",
    "                arg = params[:-2]\n",
    "                loc = params[-2]\n",
    "                scale = params[-1]\n",
    "\n",
    "                # Calculate fitted PDF and error with fit in distribution\n",
    "                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "                sse = np.sum(np.power(y - pdf, 2.0))\n",
    "\n",
    "                # if axis pass in add to plot\n",
    "                \n",
    "                try:\n",
    "                    if ax:\n",
    "                        pd.Series(pdf, x).plot(ax=ax)\n",
    "                    pass\n",
    "\n",
    "                except Exception as ex:\n",
    "                    \n",
    "                    template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "                    message = template.format(type(ex).__name__, ex.args)\n",
    "                    print(message)\n",
    "                    \n",
    "                    pass\n",
    "\n",
    "\n",
    "\n",
    "                # identify if this distribution is better\n",
    "                if best_sse > sse > 0:\n",
    "                    best_distribution = distribution\n",
    "                    best_params = params\n",
    "                    best_sse = sse\n",
    "\n",
    "\n",
    "        except Exception as ex:\n",
    "            \n",
    "            template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "            message = template.format(type(ex).__name__, ex.args)\n",
    "            print(message)\n",
    "            \n",
    "            pass\n",
    "\n",
    "    return (best_distribution.name, best_params)\n",
    "\n",
    "def make_pdf(dist, params, size=10000):\n",
    "    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n",
    "\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Get sane start and end points of distribution\n",
    "    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n",
    "    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n",
    "\n",
    "    # Build PDF and turn into pandas Series\n",
    "    x = np.linspace(start, end, size)\n",
    "    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    pdf = pd.Series(y, x)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2b1f91cbc13c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#data = pd.Series(sm.datasets.elnino.load_pandas().data.set_index('YEAR').values.ravel())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mn_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpar_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfg' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as  np\n",
    "# Load data from statsmodels datasets\n",
    "\n",
    "#data = pd.Series(sm.datasets.elnino.load_pandas().data.set_index('YEAR').values.ravel())\n",
    "\n",
    "n_cols = dfg.shape[1]\n",
    "\n",
    "par_dict={}\n",
    "\n",
    "for e in np.arange(0,n_cols,1):\n",
    "    \n",
    "    print('start '+str(dfg.iloc[:,e].name))\n",
    "\n",
    "    data = dfg.iloc[:,e].dropna().reset_index(drop=True).copy()\n",
    "    data = pd.Series(data.values.ravel())\n",
    "    \n",
    "    bins =100\n",
    "    \n",
    "    y, x = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "\n",
    "    # Plot for comparison\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = data.plot(kind='hist', bins=100, density=True, alpha=0.5)\n",
    "    # Save plot limits\n",
    "    dataYLim = ax.get_ylim()\n",
    "\n",
    "    # Find best fit distribution\n",
    "    best_fit_name, best_fit_params = best_fit_distribution(data, 100, ax)\n",
    "    best_dist = getattr(st, best_fit_name)\n",
    "    \n",
    "    print('Distribution found: '+str(best_fit_name))\n",
    "\n",
    "    # Update plots\n",
    "    ax.set_ylim(dataYLim)\n",
    "    ax.set_title(dfg.columns[e] + u'\\n All Fitted Distributions')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "    # Make PDF with best params \n",
    "    pdf = make_pdf(best_dist, best_fit_params)\n",
    "\n",
    "    # Display\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = pdf.plot(lw=2, label='PDF', legend=True)\n",
    "    data.plot(kind='hist', bins=50, density=True, alpha=0.5, label='Data', legend=True, ax=ax)\n",
    "\n",
    "    param_names = (best_dist.shapes + ', loc, scale').split(', ') if best_dist.shapes else ['loc', 'scale']\n",
    "    param_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_names, best_fit_params)])\n",
    "    dist_str = '{}({})'.format(best_fit_name, param_str)\n",
    "    \n",
    "    # export a list  \"par_list\" with all results\n",
    "    \n",
    "    dict\n",
    "    par_list = ([(k,v) for k,v in zip(param_names, best_fit_params)])\n",
    "    par_dict[dfg.columns[e] + '_'+best_fit_name] = par_list\n",
    "\n",
    "    ax.set_title(dfg.columns[e] + u'\\n' + dist_str)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTRIBUTIONS = [        \n",
    "        st.alpha,st.anglit,st.arcsine,st.beta,st.betaprime,st.bradford,st.burr,st.cauchy,st.chi,st.chi2,st.cosine,\n",
    "        st.dgamma,st.dweibull,st.erlang,st.expon,st.exponnorm,st.exponweib,st.exponpow,st.f,st.fatiguelife,st.fisk,\n",
    "        st.foldcauchy,st.foldnorm,st.frechet_r,st.frechet_l,st.genlogistic,st.genpareto,st.gennorm,st.genexpon,\n",
    "        st.genextreme,st.gausshyper,st.gamma,st.gengamma,st.genhalflogistic,st.gilbrat,st.gompertz,st.gumbel_r,\n",
    "        st.gumbel_l,st.halfcauchy,st.halflogistic,st.halfnorm,st.halfgennorm,st.hypsecant,st.invgamma,st.invgauss,\n",
    "        st.invweibull,st.johnsonsb,st.johnsonsu,st.ksone,st.kstwobign,st.laplace,st.levy,st.levy_l,st.levy_stable,\n",
    "        st.logistic,st.loggamma,st.loglaplace,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,\n",
    "        st.nct,st.norm,st.pareto,st.pearson3,st.powerlaw,st.powerlognorm,st.powernorm,st.rdist,st.reciprocal,\n",
    "        st.rayleigh,st.rice,st.recipinvgauss,st.semicircular,st.t,st.triang,st.truncexpon,st.truncnorm,st.tukeylambda,\n",
    "        st.uniform,st.vonmises,st.vonmises_line,st.wald,st.weibull_min,st.weibull_max,st.wrapcauchy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.578282604721661, -41.31285768850843, 51.888490083704056)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_fit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'σ^v_[kPa]_gamma': [('a', 5.7484772667104025),\n",
       "  ('loc', -79.74401154567104),\n",
       "  ('scale', 49.55961974402014)],\n",
       " 'PI_cauchy': [('loc', 48.13315394405227), ('scale', 25.31411714292492)],\n",
       " 'LL_cauchy': [('loc', 78.09132799206728), ('scale', 27.017437148764202)],\n",
       " 'wn_cauchy': [('loc', 41.95689437086652), ('scale', 19.78169219769638)],\n",
       " 'OCR_gamma': [('a', 0.4117660245870177),\n",
       "  ('loc', 1.9209220425804383),\n",
       "  ('scale', 82.32680334284095)],\n",
       " 'Cu-Tx_gamma': [('a', 4.578282604721661),\n",
       "  ('loc', -41.31285768850843),\n",
       "  ('scale', 51.888490083704056)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fb3aa0238504>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'par_dict.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpar_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not bytes"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file = open('par_dict.txt', 'w')\n",
    "pickle.dump(par_dict, file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
